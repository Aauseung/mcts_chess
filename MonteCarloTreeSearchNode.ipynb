{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12c3b3-3dff-4555-b6da-c154f5157388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from drawplayer import SingletonDrawPlayer\n",
    "from gamestate import GameState\n",
    "from rolloutstrategyhelper import RolloutStrategyHelper\n",
    "\n",
    "\n",
    "class MonteCarloTreeSearchNode:\n",
    "    # This action in the params is the action that the player from the parent MCTS node, i.e. the prev game state, has\n",
    "    # played. This information is critical for when we're calculating the win ratio (see below).\n",
    "    def __init__(self, game_state: GameState, parent: MonteCarloTreeSearchNode, action=None):\n",
    "        self.game_state = game_state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.children = np.array([], dtype=MonteCarloTreeSearchNode)\n",
    "        self.untried_actions = game_state.get_valid_moves()\n",
    "        self.wins = dict(map(lambda player: (player, 0), game_state.players))\n",
    "        self.wins[SingletonDrawPlayer] = 0\n",
    "        self.visits = 0\n",
    "\n",
    "    def select(self) -> MonteCarloTreeSearchNode:\n",
    "        leaf_node = self\n",
    "        while not leaf_node.is_terminal:\n",
    "            if not leaf_node.is_fully_expanded:\n",
    "                return leaf_node.expand()\n",
    "            else:\n",
    "                leaf_node = leaf_node.select_child_with_random()  #replace 'select_child_with_max_ucb' with 'select_child_with_random'\n",
    "\n",
    "        return leaf_node\n",
    "\n",
    "    def expand(self) -> MonteCarloTreeSearchNode:\n",
    "        logging.debug(f'Expanding for {self.__repr__()}')\n",
    "        action = self.untried_actions.pop()\n",
    "        new_game_state = self.game_state.make_move(action)\n",
    "        child_node = MonteCarloTreeSearchNode(new_game_state, self, action)\n",
    "        self.children = np.append(self.children, child_node)\n",
    "        logging.debug(f'Created {child_node.__repr__()}')\n",
    "        return child_node\n",
    "\n",
    "    # The learning depends highly on the rollout strategy.\n",
    "    def rollout(self):\n",
    "        logging.debug(f'Rollout now for {self.__repr__()}')\n",
    "        rollout_state = self.game_state\n",
    "        while not rollout_state.is_game_over:\n",
    "            move = MonteCarloTreeSearchNode.get_move_from_rollout_strategy(rollout_state)\n",
    "            rollout_state = rollout_state.make_move(move)\n",
    "        logging.debug(f'The winner of this rollout: {rollout_state.winner}')\n",
    "        return rollout_state.winner\n",
    "\n",
    "    def backpropagate(self, who_won):\n",
    "        self.visits += 1\n",
    "        self.wins[who_won] += 1\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(who_won)\n",
    "\n",
    "    def select_child_with_random(self):\n",
    "        return random.choice(self.children)\n",
    "    \n",
    "    # This ratio tries to maximize the winning. It doesn't try to minimize losing.\n",
    "    # def select_child_with_max_ucb(self, c) -> MonteCarloTreeSearchNode:\n",
    "    #     ucb_values = list(map(lambda child: MonteCarloTreeSearchNode.get_ucb(child, c), self.children))\n",
    "    #     return self.children[np.argmax(ucb_values)]\n",
    "\n",
    "    # @staticmethod\n",
    "    # def get_ucb(child: MonteCarloTreeSearchNode, c: float):\n",
    "    #     return child.win_ratio + c * np.sqrt(np.log(child.parent.visits) / child.visits)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_move_from_rollout_strategy(rollout_state: GameState) -> int:\n",
    "        return RolloutStrategyHelper.get_heuristic_move(rollout_state)\n",
    "\n",
    "    @property\n",
    "    def win_ratio(self):\n",
    "        if self.parent is None:  # In case it's the parent node.\n",
    "            return 0\n",
    "        # If the node hasn't been visited, then the win_ratio (part of ucb) is inf. This means it will be selected.\n",
    "        # One thing to try is wins - loses.\n",
    "        if self.visits == 0:\n",
    "            return np.inf\n",
    "        return self.wins[self.parent.game_state.current_player] / self.visits\n",
    "\n",
    "    @property\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) == len(self.game_state.get_valid_moves())\n",
    "\n",
    "    @property\n",
    "    def is_terminal(self):\n",
    "        return self.game_state.winner is not None\n",
    "\n",
    "    # def __get_self_ucb(self, c=np.sqrt(2)):\n",
    "    #     if self.parent is not None:\n",
    "    #         return self.win_ratio + c * np.sqrt(np.log(self.parent.visits) / self.visits)\n",
    "    #     return 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'TreeNode: {id(self)}'\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'TreeNode: {id(self)}, action: {self.action}, number of visits: {self.visits}, ' \\\n",
    "               #f'win ratio: {self.win_ratio}, ucb: {self.__get_self_ucb()} fully expanded: {self.is_fully_expanded}, ' \\\n",
    "               f'children: {self.children}, turn: {self.game_state.turn}, game: \\n{self.game_state}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
